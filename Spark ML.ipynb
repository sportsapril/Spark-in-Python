{"nbformat_minor": 0, "metadata": {"language_info": {"pygments_lexer": "ipython2", "name": "python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 2}, "mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.11"}, "kernelspec": {"language": "python", "name": "python2", "display_name": "Python 2 with Spark 1.6"}}, "nbformat": 4, "cells": [{"source": "# Lab 3 - Spark MLlib\n\n\"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E\"\n-Tom M. Mitchell\n\nMachine Learning - the science of getting computers to act without being explicitly programmed\n\nMLlib is Spark\u2019s machine learning (ML) library. Its goal is to make practical machine learning scalable and easy. It consists of common learning algorithms and utilities, including classification, regression, clustering, collaborative filtering (this example!), dimensionality reduction, as well as lower-level optimization primitives and higher-level pipeline APIs.\n\nIt divides into two packages:\n1. spark.mllib contains the original API built on top of RDDs.\n2. spark.ml provides higher-level API built on top of DataFrames for constructing ML pipelines.\n\n\nUsing spark.ml is recommended because with DataFrames the API is more versatile and flexible. But we will keep supporting spark.mllib along with the development of spark.ml. Users should be comfortable using spark.mllib features and expect more features coming.\n\nhttp://spark.apache.org/docs/latest/mllib-guide.html\n\n## Online Purchase Recommendations\n\nLearn how to create a recommendation engine using the Alternating Least Squares algorithm in Spark's machine learning library\n\n<img src='https://raw.githubusercontent.com/rosswlewis/RecommendationPoT/master/ALS.png' width=\"70%\" height=\"70%\"></img>\n\n## The data\n\nThis is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.  The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n\nhttp://archive.ics.uci.edu/ml/datasets/Online+Retail\n\n<img src='https://raw.githubusercontent.com/rosswlewis/RecommendationPoT/master/FullFile.png' width=\"80%\" height=\"80%\"></img>", "metadata": {}, "cell_type": "markdown"}, {"source": "## Step 1 - Create an RDD from the CSV File \n### 1.1 - Download the data", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 1, "outputs": [{"name": "stdout", "output_type": "stream", "text": "--2017-03-09 15:58:46--  https://raw.githubusercontent.com/rosswlewis/RecommendationPoT/master/OnlineRetail.csv.gz\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 7483128 (7.1M) [application/octet-stream]\nSaving to: \u2018OnlineRetail.csv.gz\u2019\n\n100%[======================================>] 7,483,128   34.5MB/s   in 0.2s   \n\n2017-03-09 15:58:46 (34.5 MB/s) - \u2018OnlineRetail.csv.gz\u2019 saved [7483128/7483128]\n\n"}], "source": "#Download the data from github to the local directory\n!rm 'OnlineRetail.csv.gz' -f\n!wget https://raw.githubusercontent.com/rosswlewis/RecommendationPoT/master/OnlineRetail.csv.gz", "metadata": {"collapsed": false, "scrolled": false}, "cell_type": "code"}, {"source": "### 1.2 - Put the csv into an RDD (at first, each row in the RDD is a string which correlates to a line in the csv) and show the first three lines.\n<br>\n <div class=\"panel-group\" id=\"accordion-12\">\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-1\" href=\"#collapse1-12\">\n        Hint 1</a>\n      </h4>\n    </div>\n    <div id=\"collapse1-12\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Use the Spark context (sc) to get the list of possible methods.  <i>sc.&lt;TAB&gt;</i></div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-12\" href=\"#collapse2-12\">\n        Hint 2</a>\n      </h4>\n    </div>\n    <div id=\"collapse2-12\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Use the <i>textFile()</i> method</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-12\" href=\"#collapse3-12\">\n        Hint 3</a>\n      </h4>\n    </div>\n    <div id=\"collapse3-12\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Type:<br>\nloadRetailData = sc.textFile(\"OnlineRetail.csv.gz\")<br>\nloadRetailData.take(3)<br></div>\n    </div>\n  </div>\n</div> \n\n", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 2, "outputs": [], "source": "res = sc.textFile('OnlineRetail.csv.gz')", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "## Step 2 - Prepare and shape the data:  \"80% of a Data Scientists  job\"", "metadata": {}, "cell_type": "markdown"}, {"source": "### 2.1 - Remove the header from the RDD and split the remaining lines by comma.\n<br>\n <div class=\"panel-group\" id=\"accordion-21\">\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-21\" href=\"#collapse1-21\">\n        Hint 1</a>\n      </h4>\n    </div>\n    <div id=\"collapse1-21\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">The header is the first line in the RDD -- use <i>first()</i> to obtain it.</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-21\" href=\"#collapse2-21\">\n        Hint 2</a>\n      </h4>\n    </div>\n    <div id=\"collapse2-21\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Use the <i>filter()</i> method to filter out all lines which are not equal to the header line.</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-21\" href=\"#collapse3-21\">\n        Hint 3</a>\n      </h4>\n    </div>\n    <div id=\"collapse3-21\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Map the <i>split()</i> method to the remaining lines to split on \",\"</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-21\" href=\"#collapse4-21\">\n        Hint 4</a>\n      </h4>\n    </div>\n    <div id=\"collapse4-21\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Type:<br>\n\nheader = loadRetailData.first()<br>\nsplitColumns = loadRetailData.filter(lambda line: line != header).map(lambda l: l.split(\",\"))</div>\n    </div>\n  </div>\n</div> ", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 86, "outputs": [], "source": "header = res.take(1)[0]\ndata = res.filter(lambda line: line != header)", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 87, "outputs": [], "source": "data = data.map(lambda x: x.split(\",\"))", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "### 2.2 - Filter the remaining lines using <a href=\"https://docs.python.org/2.6/howto/regex.html\">regular expressions</a>\nThe original file at UCI's Machine Learning Repository has commas in the product description.  Those have been removed to expediate the lab.\nOnly keep rows that have a quantity greater than 0, a non-empty customerID, and a non-blank stock code after removing non-numeric characters.<br><br>\n <div class=\"panel-group\" id=\"accordion-22\">\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-22\" href=\"#collapse1-22\">\n        Hint 1</a>\n      </h4>\n    </div>\n    <div id=\"collapse1-22\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Examine the header to determine which fields need to be used to filter the data.</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-22\" href=\"#collapse2-22\">\n        Hint 2</a>\n      </h4>\n    </div>\n    <div id=\"collapse2-22\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Use the <i>filter()</i> method for the first two requirements.   Note -- you may have to cast values.</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-22\" href=\"#collapse3-22\">\n        Hint 3</a>\n      </h4>\n    </div>\n    <div id=\"collapse3-22\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Look at the <i><a href=\"https://docs.python.org/2.6/howto/regex.html\">re.sub()</a></i> method</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-22\" href=\"#collapse4-22\">\n        Hint 4</a>\n      </h4>\n    </div>\n    <div id=\"collapse4-22\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Type:<br>\nimport re<br>\nfilteredRetailData = splitColumns.filter(lambda l: int(l[3]) > 0 and len(re.sub(\"\\D\", \"\", l[1])) != 0 and l[6] != \"\")</div>\n    </div>\n  </div>\n</div> ", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 89, "outputs": [], "source": "#filteredRetailData = splitColumns.filter(lambda l: int(l[3]) > 0 and len(re.sub(\"\\D\", \"\", l[1])) != 0 and l[6] != \"\")\n#dataFiltered = data.filter(lambda l: int(l[3]) > 0 and len(re.sub(\"\\D\", \"\", l[1])) != 0 and l[6] != \"\")", "metadata": {"collapsed": true}, "cell_type": "code"}, {"execution_count": 91, "outputs": [{"execution_count": 91, "output_type": "execute_result", "data": {"text/plain": "u'InvoiceNo,StockCode,Description,Quantity,InvoiceDate,UnitPrice,CustomerID,Country'"}, "metadata": {}}], "source": "header", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 84, "outputs": [], "source": "import re\ndataFiltered = data.filter(lambda x: x[3] > 0 and x[6] != \"\" and len(re.sub('\\D','',x[1])) > 0)\n", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "###  2.3 - Map each line to a SQL Row and create a Dataframe from the result.   Register the Dataframe as an SQL temp table.\n<br>\nUse the following for the Row column names: inv, stockCode, description, quant, invDate, price, custId, country.   inv, stockCode, quant and custId should be integers.   \nprice is a float.  description and country are strings (the default).\n<br><br>\nHint: When you replaced non-digit characters using the regular expression above, you replaced them in the context of a test.  You'll have to do it again when creating the stockCode Row value.\n<br><br>\n <div class=\"panel-group\" id=\"accordion-23\">\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-23\" href=\"#collapse1-23\">\n        Hint 1</a>\n      </h4>\n    </div>\n    <div id=\"collapse1-23\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">We haven't used SQLContext or Row in this notebook, so you will have to import them from the pyspark.sql package and then create a <i>SQLContext</i>.</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-23\" href=\"#collapse2-23\">\n        Hint 2</a>\n      </h4>\n    </div>\n    <div id=\"collapse2-23\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">You can create a <i>Row</i> using a <i>map()</i>.   For example:<br>\n      example = myRDD.map(lambda x: Row(v1=x[1], v2=int(x[2]), v3=float(x[3]))<br>\n      Note how we set the column names this way.</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-23\" href=\"#collapse3-23\">\n        Hint 3</a>\n      </h4>\n    </div>\n    <div id=\"collapse3-23\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">use <i>createDataFrame()</i> in your <i>SQLContext</i>.   Then register the dataframe with <i>registerTempTable()</i></div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-23\" href=\"#collapse4-23\">\n        Hint 4</a>\n      </h4>\n    </div>\n    <div id=\"collapse4-23\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Type:<br>\nfrom pyspark.sql import SQLContext, Row<br>\nsqlContext = SQLContext(sc)<br>\n\nretailRows = filteredRetailData.map(lambda l: Row(inv=int(l[0]), stockCode=int(re.sub(\"\\D\", \"\", l[1])), description=l[2], quant=int(l[3]), invDate=l[4], price=float(l[5]), custId=int(l[6]), country=l[7]))<br>\n\nretailDf = sqlContext.createDataFrame(retailRows)<br>\nretailDf.registerTempTable(\"retailPurchases\")</div>\n    </div>\n  </div>\n</div> ", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 92, "outputs": [], "source": "from pyspark.sql import SQLContext, Row\nsqlContext = SQLContext(sc)\nretailRows = dataFiltered.map(lambda l: Row(inv=int(l[0]), stockCode=int(re.sub(\"\\D\", \"\", l[1])), description=l[2], quant=int(l[3]), invDate=l[4], price=float(l[5]), custId=int(l[6]), country=l[7]))\nretailDf = sqlContext.createDataFrame(retailRows)\nretailDf.registerTempTable(\"retailPurchases\")", "metadata": {"collapsed": true}, "cell_type": "code"}, {"execution_count": 97, "outputs": [], "source": "test = sqlContext.sql('select * from retailPurchases limit 5').toPandas()", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 68, "outputs": [{"execution_count": 68, "output_type": "execute_result", "data": {"text/plain": "u'InvoiceNo,StockCode,Description,Quantity,InvoiceDate,UnitPrice,CustomerID,Country'"}, "metadata": {}}], "source": "header", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 70, "outputs": [], "source": "#data_df = sqlContext.createDataFrame(data)", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 71, "outputs": [], "source": "#data_df.registerTempTable('dataset')", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 94, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------------+-----------+\n|      tableName|isTemporary|\n+---------------+-----------+\n|retailPurchases|       true|\n+---------------+-----------+\n\n"}], "source": "sqlContext.tables().show()", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "### 2.4 - Keep only the data we need (custId, stockCode, and rank)\n<br>\nThe Alternating Least Squares algorithm requires three values.   In this case, we're going to use the Customer ID (custId), stock code (stockCode) and a ranking value.   In this situation there is not a ranking value within the data, so we will create one.   We will set a value of 1 to indicate a purchase since these are all actual orders.   Set that value to \"purch\".\n<br><br>\nAfter doing the select, group by custId and stockCode.\n<br><br>\n <div class=\"panel-group\" id=\"accordion-24\">\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-24\" href=\"#collapse1-24\">\n        Hint 1</a>\n      </h4>\n    </div>\n    <div id=\"collapse1-24\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">To add a fixed value within a select statement, use something like <i>select x,y,1 as purch from z</i></div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-24\" href=\"#collapse2-24\">\n        Hint 2</a>\n      </h4>\n    </div>\n    <div id=\"collapse2-24\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Use the <i>group by</i> statement to group results.  To group by two values, separate them by commas (i.e. <i>group by x,y</i>)</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-24\" href=\"#collapse3-24\">\n        Hint 3</a>\n      </h4>\n    </div>\n    <div id=\"collapse3-24\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Type:\n\nquery = \"\nSELECT \n    custId, stockCode, 1 as purch\nFROM \n    retailPurchases \ngroup \n    by custId, stockCode\"<br>\nuniqueCombDf = sqlContext.sql(query)</div>\n    </div>\n  </div>\n</div> ", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 100, "outputs": [], "source": "uniqueComb = sqlContext.sql('select custId, stockCode, 1 as purch from retailPurchases group by custId, stockCode')", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "### 2.5 - Randomly split the data into a testing set (10% of the data), a cross validation set (10% of the data) a training set (80% of the data)\n<br><br>\nWe wish to split up the data into three parts.   A training set (80%) to train the algorithm, a testing set (10%) and a cross-validation set (10%).   The data for each set should be randomly selected.\n<br><br>\n <div class=\"panel-group\" id=\"accordion-25\">\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-25\" href=\"#collapse1-25\">\n        Hint 1</a>\n      </h4>\n    </div>\n    <div id=\"collapse1-25\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Use the <i><a href=\"https://spark.apache.org/docs/1.6.2/api/python/pyspark.sql.html#pyspark.sql.DataFrame.randomSplit\">randomSplit()</a></i> method</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-25\" href=\"#collapse2-25\">\n        Hint 2</a>\n      </h4>\n    </div>\n    <div id=\"collapse2-25\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Type:<br>\n      testDf, cvDf, trainDf = uniqueCombDf.randomSplit([.1,.1,.8])<br></div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-25\" href=\"#collapse3-25\">\n        Advanced Optional 1</a>\n      </h4>\n    </div>\n    <div id=\"collapse3-25\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\"><i>randomSplit()</i> takes an optional seed parameter.  At the end of the exercise give a random seed and see whether the results change.</div>\n    </div>\n  </div>\n</div> ", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 106, "outputs": [], "source": "testDf, cvDf, trainDf = uniqueComb.randomSplit([.1,.1,.8])\n", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "## Step 3 - Build recommendation models\n\n### 3.1 - Use the training dataframe to train a model with Alternating Least Squares using the <i><a href=\"https://spark.apache.org/docs/1.6.1/api/python/pyspark.ml.html#pyspark.ml.recommendation.ALS\">ALS</a></i> class\n<br>\nALS attempts to estimate the ratings matrix R as the product of two lower-rank matrices, X and Y, i.e. X * Yt = R. Typically these approximations are called \u2018factor\u2019 matrices. The general approach is iterative. During each iteration, one of the factor matrices is held constant, while the other is solved for using least squares. The newly-solved factor matrix is then held constant while solving for the other factor matrix.\n<br><br>\nLatent Factors / rank<br>\n&nbsp;&nbsp;&nbsp;&nbsp;The number of columns in the user-feature and product-feature matricies<br>\nIterations / maxIter<br>\n&nbsp;&nbsp;&nbsp;&nbsp;The number of factorization runs<br><br>\nTo use the ALS class type:\n<br>\nfrom pyspark.ml.recommendation import ALS<br>\n<br>\nWhen running ALS, we need to create two separate instances.   For both instances userCol is custId, itemCol is stockCode and ratingCol is purch.<br><br>\nFor the first instance, use a rank of 15 and set iterations to 5.<br>\nFor the second instance, use a rank of 2 and set iterations to 10.<br>\nRun <i><a href=\"https://spark.apache.org/docs/1.6.1/api/python/pyspark.ml.html#pyspark.ml.recommendation.ALS.fit\">fit()</a></i> on both instances using the training dataframe.<br>\n<br>\n <div class=\"panel-group\" id=\"accordion-31\">\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-31\" href=\"#collapse1-31\">\n        Advanced Optional 1</a>\n      </h4>\n    </div>\n    <div id=\"collapse1-31\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Create an emply instance of the <i>ALS</i> class and run the <i>explainParams</i> method on it to see the default values.</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-31\" href=\"#collapse2-31\">\n        Hint 1</a>\n      </h4>\n    </div>\n    <div id=\"collapse2-31\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">als1 = ALS(rank=15, maxIter=5, userCol=\"custId\", itemCol=\"stockCode\", ratingCol=\"purch\")</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-31\" href=\"#collapse3-31\">\n        Hint 2</a>\n      </h4>\n    </div>\n    <div id=\"collapse3-31\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">model1 = als1.fit(trainDf)</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-31\" href=\"#collapse4-31\">\n        Hint 3</a>\n      </h4>\n    </div>\n    <div id=\"collapse4-31\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Type:\n<br>\nfrom pyspark.ml.recommendation import ALS<br>\n\nals1 = ALS(rank=15, maxIter=5, userCol=\"custId\", itemCol=\"stockCode\", ratingCol=\"purch\")<br>\nmodel1 = als1.fit(trainDf)<br>\n\nals2 = ALS(rank=2, maxIter=10, userCol=\"custId\", itemCol=\"stockCode\", ratingCol=\"purch\")<br>\nmodel2 = als2.fit(trainDf)\n</div>\n    </div>\n  </div>\n</div> \n", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 114, "outputs": [], "source": "from pyspark.ml.recommendation import ALS\nals1 = ALS(rank = 15, maxIter=5,userCol = 'custId',itemCol = 'stockCode',ratingCol='purch')\nals2 = ALS(rank = 10, maxIter=2,userCol = 'custId',itemCol = 'stockCode',ratingCol='purch')", "metadata": {"collapsed": false, "scrolled": true}, "cell_type": "code"}, {"execution_count": 115, "outputs": [], "source": "model1 = als1.fit(trainDf)\n", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 116, "outputs": [{"execution_count": 116, "output_type": "execute_result", "data": {"text/plain": "ALS_48039ccab8a1663f9df5"}, "metadata": {}}], "source": "model1", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 117, "outputs": [], "source": "model2 = als2.fit(trainDf)", "metadata": {"collapsed": true}, "cell_type": "code"}, {"source": "## Step 4 - Test the models\n\nUse the models to predict what the user will rate a certain item.  The closer our model is to 1 for an item a user has already purchased, the better.\n\n### 4.1 - Evaluate the model with the cross validation dataframe by using the transorm function.\n\nSome of the users or purchases in the cross validation data may not have been in the training data.  Let's remove the ones that aren't.   To do this obtain all the the custId and stockCode values from the training data and filter out any lines with those values from the cross-validation data.\n<br><br>\nAt the end, print out how many cross-validation lines we had at the start -- and the new number afterwords.\n<br><br>\n <div class=\"panel-group\" id=\"accordion-41\">\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-41\" href=\"#collapse1-41\">\n        Hint 1</a>\n      </h4>\n    </div>\n    <div id=\"collapse1-41\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Use <i>map()</i> to return a specific value (i.e. foo = foo.map(lambda x: x.value)) and put them all in a set (i.e. foo1 = set(foo))<br></div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-41\" href=\"#collapse2-41\">\n        Hint 2</a>\n      </h4>\n    </div>\n    <div id=\"collapse2-41\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">You need all the returned values (remember they might be spread all across the cluster!) so run collect() on the results of the map(). (i.e. foo1 = set(foo.collect()))</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-41\" href=\"#collapse3-41\">\n        Hint 3</a>\n      </h4>\n    </div>\n    <div id=\"collapse3-41\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Use the <i>filter()</i> to filter out any values in the cross-validation dataframe which are in the stockCode or custId sets.   Use <i>toDF()</i> to change the results to a dataframe.</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-41\" href=\"#collapse4-41\">\n        Hint 4</a>\n      </h4>\n    </div>\n    <div id=\"collapse4-41\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Type:<br>\ncustomers = set(trainDf.rdd.map(lambda line: line.custId).collect())<br>\nstock = set(trainDf.rdd.map(lambda line: line.stockCode).collect())<br>\n\nfilteredCvDf = cvDf.rdd.filter(lambda line: line.stockCode in stock and line.custId in customers).toDF()<br>\n\nprint cvDf.count()<br>\nprint filteredCvDf.count()<br></div>\n    </div>\n  </div>\n</div> ", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 120, "outputs": [], "source": "customers = set(trainDf.rdd.map(lambda line:line.custId).collect())\n", "metadata": {"collapsed": false, "scrolled": true}, "cell_type": "code"}, {"execution_count": 125, "outputs": [], "source": "stockCode = set(trainDf.rdd.map(lambda line:line.stockCode).collect())\n", "metadata": {"collapsed": true}, "cell_type": "code"}, {"execution_count": 199, "outputs": [{"execution_count": 199, "output_type": "execute_result", "data": {"text/plain": "3173"}, "metadata": {}}], "source": "len(stockCode)", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 128, "outputs": [], "source": "cvDfFiltered = cvDf.rdd.filter(lambda line: line.stockCode in stockCode and line.custId in customers).toDF()", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 129, "outputs": [{"execution_count": 129, "output_type": "execute_result", "data": {"text/plain": "26100"}, "metadata": {}}], "source": "cvDfFiltered.count()", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "### Step 4.2 - Make Predictions using <i><a href=\"https://spark.apache.org/docs/1.6.1/api/python/pyspark.ml.html#pyspark.ml.recommendation.ALSModel.transform\">transform()</a></i>\n\nType:\n\npredictions1 = model1.transform(filteredCvDf)<br>\npredictions2 = model2.transform(filteredCvDf)\n</font>", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 131, "outputs": [], "source": "predictions1 = model1.transform(cvDfFiltered)\n", "metadata": {"collapsed": false, "scrolled": false}, "cell_type": "code"}, {"execution_count": 132, "outputs": [], "source": "predictions2 = model2.transform(cvDfFiltered)\n", "metadata": {"collapsed": true}, "cell_type": "code"}, {"source": "### 4.3 - Calculate and print the Mean Squared Error.   For all ratings, subtract the prediction from the actual purchase (1), square the result, and take the mean of all of the squared differences.\n\nThe lower the result number, the better the model.\n\nType:\n\nmeanSquaredError1 = predictions1.map(lambda line: (line.purch - line.prediction)\\*\\*2).mean()<br>\nmeanSquaredError2 = predictions2.map(lambda line: (line.purch - line.prediction)\\*\\*2).mean()<br><br>\n    \nprint 'Mean squared error = %.4f for our first model' % meanSquaredError1<br>\nprint 'Mean squared error = %.4f for our second model' % meanSquaredError2\n", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 139, "outputs": [], "source": "meanSquaredError1 = predictions1.map(lambda x: (x.purch - x.prediction)**2).mean()\n", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 138, "outputs": [{"execution_count": 138, "output_type": "execute_result", "data": {"text/plain": "0.009860362057354544"}, "metadata": {}}], "source": "meanSquaredError2 = predictions2.map(lambda x: (x.purch - x.prediction)**2).mean()", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "### 4.4 - Confirm the model by testing it with the test data and the best hyperparameters found during cross-validation\n\nFilter the test dataframe (testDf) the same way as the cross-validation dataframe.   Then run the transform() and calculate the mean squared error.   It should be the same as the value calcuated above.\n\nType:\n\nfilteredTestDf = testDf.rdd.filter(lambda line: line.stockCode in stock and line.custId in customers).toDF()<br>\npredictions3 = model2.transform(filteredTestDf)<br>\nmeanSquaredError3 = predictions3.map(lambda line: (line.purch - line.prediction)\\*\\*2).mean()<br><br>\n    \nprint 'Mean squared error = %.4f for our best model' % meanSquaredError3\n", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 141, "outputs": [], "source": "\nfilteredTestDf = testDf.rdd.filter(lambda line: line.stockCode in stockCode and line.custId in customers).toDF()\npredictions3 = model2.transform(filteredTestDf)\nmeanSquaredError3 = predictions3.map(lambda line: (line.purch - line.prediction)**2).mean()\n", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 142, "outputs": [{"execution_count": 142, "output_type": "execute_result", "data": {"text/plain": "0.010599710080619256"}, "metadata": {}}], "source": "meanSquaredError3", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 182, "outputs": [{"execution_count": 182, "output_type": "execute_result", "data": {"text/plain": "Row(custId=16210, stockCode=20977, purch=1)"}, "metadata": {}}], "source": "filteredTestDf.first()", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 188, "outputs": [{"execution_count": 188, "output_type": "execute_result", "data": {"text/plain": "Row(stockCode=84519, custId=15544)"}, "metadata": {}}], "source": "singleTest.first()", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "## Step 5 - Implement the model\n\n### 5.1 - First, create a dataframe in which each row has the user id and an item id.\n<br>\nUse the <i><a href=\"https://spark.apache.org/docs/1.6.2/api/python/pyspark.sql.html#pyspark.sql.DataFrame\">Dataframe</a></i> methods to create a Dataframe with a specific user and that user's purchased products.<br>\n&nbsp;&nbsp;&nbsp;&nbsp;First, use the Dataframe <i><a href=\"https://spark.apache.org/docs/1.6.2/api/python/pyspark.sql.html#pyspark.sql.DataFrame.filter\">filter()</a></i> to filter out all custId's but 15544.<br>\n&nbsp;&nbsp;&nbsp;&nbsp;Then use the <i><a href=\"https://spark.apache.org/docs/1.6.2/api/python/pyspark.sql.html#pyspark.sql.DataFrame.select\">select()</a></i> to only return the <i>custId</i> column.<br>\n&nbsp;&nbsp;&nbsp;&nbsp;Now use <i><a href=\"https://spark.apache.org/docs/1.6.2/api/python/pyspark.sql.html#pyspark.sql.DataFrame.distinct\">distinct()</a></i> to ensure we only have the single custId.<br>\n&nbsp;&nbsp;&nbsp;&nbsp;Do a <i><a href=\"https://spark.apache.org/docs/1.6.2/api/python/pyspark.sql.html#pyspark.sql.DataFrame.join\">join()</a></i> with the distinct values from the stockCode column.\n<br><br>\n <div class=\"panel-group\" id=\"accordion-51\">\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-51\" href=\"#collapse1-51\">\n        Hint 1</a>\n      </h4>\n    </div>\n    <div id=\"collapse1-51\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Use the Dataframe <i>filter()</i> method to filter out all users but 15544<br>\n      user = trainDf.filter(trainDf.custId == 15544)<br></div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-51\" href=\"#collapse2-51\">\n        Hint 2</a>\n      </h4>\n    </div>\n    <div id=\"collapse2-51\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Use the Dataframe <i>select()</i> method to only select the custId column<br>\n      userCustId = user.select(\"custId\")</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-51\" href=\"#collapse3-51\">\n        Hint 3</a>\n      </h4>\n    </div>\n    <div id=\"collapse3-51\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Use the Dataframe <i>distinct()</i> method to only return unique rows.<br>\n      userCustIdDistinct = userCustId.distinct()</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-51\" href=\"#collapse4-51\">\n        Hint 4</a>\n      </h4>\n    </div>\n    <div id=\"collapse4-51\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Use the Dataframe <i>join()</i> method to join the results with distinct stockCodes</div>\n    </div>\n  </div>\n    <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-51\" href=\"#collapse4-51\">\n        Hint 5</a>\n      </h4>\n    </div>\n    <div id=\"collapse5-51\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Type:<br>\nuser = trainDf.filter(trainDf.custId == 15544)<br>\nuserCustId = user.select(\"custId\")<br>\nuserCustIdDistinct = userCustId.distinct()<br>\nstockCode = trainDf.select(\"stockCode\")<br>\nstockCodeDistinct = stockCode.distinct()<br>\nuserItems = userCustIdDistinct.join(stockCodeDistinct)<br>\nOR\nuserItems = trainDf.filter(trainDf.custId == 15544).select(\"custId\").distinct().join( trainDf.select(\"stockCode\").distinct())<br></div>\n    </div>\n  </div>\n</div> ", "metadata": {}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": "user = trainDf.filter(trainDf.custId == 15544)\n", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 167, "outputs": [], "source": "userCustId = user.select(\"custId\")", "metadata": {"collapsed": true}, "cell_type": "code"}, {"execution_count": 168, "outputs": [], "source": "userCustIdDistinct = userCustId.distinct()", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 207, "outputs": [], "source": "singleTest = sqlContext.sql('SELECT distinct stockCode from retailPurchases')", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": "singleTest.join(userCustIdDistinct).first()", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "### 5.2 - Use 'transform' to rate each item.\n\nType:\n\nbestRecsDf = model2.transform(userItems)\nbestRecsDf.first()\n", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 189, "outputs": [], "source": "bestRecsDf = model2.transform(singleTest)\n", "metadata": {"collapsed": false}, "cell_type": "code"}, {"execution_count": 191, "outputs": [{"execution_count": 191, "output_type": "execute_result", "data": {"text/plain": "[Row(stockCode=20831, custId=15544, prediction=0.9443859457969666),\n Row(stockCode=21031, custId=15544, prediction=0.7434231638908386),\n Row(stockCode=21231, custId=15544, prediction=0.8711667060852051),\n Row(stockCode=21631, custId=15544, prediction=0.6014509201049805),\n Row(stockCode=22031, custId=15544, prediction=0.8843409419059753),\n Row(stockCode=22231, custId=15544, prediction=0.8970155715942383),\n Row(stockCode=22431, custId=15544, prediction=0.9440104365348816),\n Row(stockCode=22631, custId=15544, prediction=0.9811267852783203),\n Row(stockCode=22831, custId=15544, prediction=0.9202867746353149),\n Row(stockCode=23031, custId=15544, prediction=0.9412189722061157)]"}, "metadata": {}}], "source": "bestRecsDf.take(10)", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "###  5.3 - Print the top 5 recommendations sorted on prediction.\n\n <div class=\"panel-group\" id=\"accordion-53\">\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-53\" href=\"#collapse1-53\">\n        Hint 1</a>\n      </h4>\n    </div>\n    <div id=\"collapse1-53\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">In order to print the top five recommendations, we need to <i><a href\"https://spark.apache.org/docs/1.6.2/api/python/pyspark.sql.html#pyspark.sql.DataFrame.sort\">sort()</a></i> them in descending order<br></div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-53\" href=\"#collapse2-53\">\n        Hint 2</a>\n      </h4>\n    </div>\n    <div id=\"collapse2-53\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Use <i>take()</i> to get the top 5 values.</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-53\" href=\"#collapse3-53\">\n        Hint 3</a>\n      </h4>\n    </div>\n    <div id=\"collapse3-53\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">Type:<br>\n      print bestRecsDf.sort(\"prediction\",ascending=False).take(5)</div>\n    </div>\n  </div>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\">\n        <a data-toggle=\"collapse\" data-parent=\"#accordion-53\" href=\"#collapse4-53\">\n        Advanced Optional 1</a>\n      </h4>\n    </div>\n    <div id=\"collapse4-53\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\">select from the retailPurchases temp table on stockCode to see some of selections recommended.</div>\n    </div>\n  </div>\n</div> ", "metadata": {}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": "bestRecsDf", "metadata": {"collapsed": true}, "cell_type": "code"}, {"execution_count": 193, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Row(stockCode=90133, custId=15544, prediction=-0.6156840324401855), Row(stockCode=90042, custId=15544, prediction=-0.4631926119327545), Row(stockCode=90136, custId=15544, prediction=-0.4631926119327545), Row(stockCode=90179, custId=15544, prediction=-0.4631926119327545), Row(stockCode=90194, custId=15544, prediction=-0.3413624167442322)]\n"}], "source": "print bestRecsDf.sort(\"prediction\",ascending=True).take(5)", "metadata": {"collapsed": false, "scrolled": true}, "cell_type": "code"}, {"source": "Let's look up this user and the recommended product ID's in the excel file...\n\n<img src='https://raw.githubusercontent.com/rosswlewis/RecommendationPoT/master/user.png' width=\"80%\" height=\"80%\"></img>", "metadata": {}, "cell_type": "markdown"}, {"source": "This user seems to have purchased a lot of childrens gifts and some holiday items.  The recommendation engine we created suggested some items along these lines\n", "metadata": {"collapsed": true}, "cell_type": "markdown"}, {"source": "#####  Citation\nDaqing Chen, Sai Liang Sain, and Kun Guo, Data mining for the online retail industry: A case study of RFM model-based customer segmentation using data mining, Journal of Database Marketing and Customer Strategy Management, Vol. 19, No. 3, pp. 197\u00e2\u20ac\u201c208, 2012 (Published online before print: 27 August 2012. doi: 10.1057/dbm.2012.17).", "metadata": {}, "cell_type": "markdown"}]}